# human-centered-llm-lab
# Human-Centered LLM Lab — by Alesse Nunes
## Open Research Initiative (2026–2027)

**Project title:** *Building and Deploying a Human-Centered Large Language Model from Scratch in Japan (2026–2027)*

This repository is a public, 12-month experiment to **understand**, **implement**, **evaluate**, and **deploy** a human-centered large language model system—from first principles to production.

I am not “studying AI.”  
I am running an **open lab**: every architectural decision, experiment, metric, failure, and iteration is documented.

---

## What “from scratch” means here
- A tokenizer is trained from scratch (no borrowed vocab).
- A decoder-only Transformer is implemented in PyTorch.
- Model weights are initialized randomly and trained (no pre-trained checkpoint).
- Evaluation + deployment are treated as first-class citizens.

---

## Lab pillars
- **Foundations:** tensors, gradients, loss, attention mechanics
- **Model engineering:** tokenization, training stability, evaluation
- **Systems:** API, streaming inference, deployment, monitoring, cost
- **Human-centered layer:** safety, autonomy, psychological risk, ethical boundaries

---

## Start here
- **Manifesto:** `manifesto.md`
- **Principles:** `principles.md`
- **Roadmap (2026–2027):** `roadmap_2026_2027.md`
- **Experiment log:** `experiments_log/`

---

## Status
- **Day 001:** Initial lab setup + experiment protocol

---

## Contact / Collaboration
If you want to discuss research, production systems, or human-centered evaluation: open an Issue.
